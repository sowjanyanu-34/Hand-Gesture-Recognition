# âœ‹ Hand Gesture Recognition System

A real-time **Hand Gesture Recognition** system built using **Python, Computer Vision, and Machine Learning**.
This project detects and classifies hand gestures through a webcam and predicts gestures such as ğŸ‘ thumbs up and ğŸ‘ thumbs down.

---

## ğŸ“Œ Project Overview

This system captures hand landmarks using computer vision techniques and trains a machine learning model to recognize different gestures.

It can be used for:

* Human-computer interaction
* Assistive communication
* Touchless control systems
* Sign language basics

---

## ğŸš€ Features

âœ… Real-time hand tracking using webcam
âœ… Custom gesture data collection
âœ… Machine learning model training
âœ… Live gesture prediction
âœ… Easy to extend with new gestures

---

## ğŸ› ï¸ Technologies Used

* **Python**
* **OpenCV**
* **MediaPipe**
* **NumPy**
* **Scikit-learn**

---

## ğŸ“ Project Structure

```
Hand-Gesture-Recognition/
â”‚
â”œâ”€â”€ dataset/            # CSV gesture data
â”œâ”€â”€ collect_data.py     # Collect gesture samples
â”œâ”€â”€ train_model.py      # Train ML model
â”œâ”€â”€ predict.py          # Predict gestures in real time
â”œâ”€â”€ hand_test.py        # Test hand detection
â”œâ”€â”€ model.pkl           # Trained model (generated after training)
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```
git clone https://github.com/sowjanyanu-34/Hand-Gesture-Recognition.git
cd Hand-Gesture-Recognition
```

### 2ï¸âƒ£ Create virtual environment

```
python -m venv venv
```

### 3ï¸âƒ£ Activate virtual environment

**Windows**

```
venv\Scripts\activate
```

**Mac/Linux**

```
source venv/bin/activate
```

### 4ï¸âƒ£ Install dependencies

```
pip install opencv-python mediapipe numpy scikit-learn
```

---

## ğŸ“Š How to Use

### â–¶ï¸ Step 1: Collect gesture data

```
python collect_data.py
```

Capture samples for each gesture.

---

### â–¶ï¸ Step 2: Train the model

```
python train_model.py
```

This creates:

```
model.pkl
```

---

### â–¶ï¸ Step 3: Run gesture prediction

```
python predict.py
```

The webcam will open and display predicted gestures.

---

## â• Adding New Gestures

1. Collect data for the new gesture
2. Update labels if required
3. Retrain the model
4. Run prediction again

---

## ğŸ¯ Applications

* Sign language assistance
* Gesture-based controls
* Smart home automation
* Interactive gaming
* Accessibility tools

---

## ğŸ“¸ Demo (Add Screenshot Here)

You can add screenshots or GIFs showing gesture detection.

Example:

```
![Demo](images/demo.png)
```

---

## ğŸ‘©â€ğŸ’» Author

**Sowjanya N U**
Computer Science Engineering Student

---

## â­ Future Improvements

* Support more gestures
* Improve accuracy with deep learning
* Deploy as a web app
* Mobile integration

---

## ğŸ“œ License

This project is open-source and available for educational use.

---

â­ If you like this project, give it a star!
